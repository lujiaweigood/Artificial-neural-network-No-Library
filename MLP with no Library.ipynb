{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "#from sklearn.datasets import fetch_mldata, fetch_openml\n",
    "from sklearn.datasets import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(34)\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "\n",
    "x_mnist = mnist.data.astype('float32') / 255.\n",
    "t_mnist = np.eye(10)[mnist.target.astype('int32')]\n",
    "\n",
    "x_train_mnist, x_test_mnist, t_train_mnist, t_test_mnist = train_test_split(x_mnist, t_mnist, test_size=10000)\n",
    "x_train_mnist, x_valid_mnist, t_train_mnist, t_valid_mnist = train_test_split(x_train_mnist, t_train_mnist, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def deriv_relu(x):\n",
    "    return (x > 0).astype(x.dtype)\n",
    "def np_log(x):\n",
    "    return np.log(np.clip(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x -= x.max(axis=1, keepdims=True)\n",
    "    x_exp = np.exp(x)\n",
    "    return x_exp / np.sum(x_exp, axis=1, keepdims=True)\n",
    "\n",
    "def deriv_softmax(x):\n",
    "    return softmax() * (1 - softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "        self.W = np.random.uniform(low=-0.08, high=0.08,\n",
    "                                   size=(in_dim, out_dim)).astype('float64')\n",
    "        self.b = np.zeros(out_dim).astype('float64')\n",
    "        self.function = function\n",
    "        self.deriv_function = deriv_function\n",
    "        \n",
    "        self.x = None\n",
    "        self.u = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "        self.params_idxs = np.cumsum([self.W.size, self.b.size])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.matmul(self.x, self.W) + self.b\n",
    "        return self.function(self.u)\n",
    "\n",
    "    def b_prop(self, delta, W):\n",
    "        self.delta = self.deriv_function(self.u) * np.matmul(delta, W.T)\n",
    "        return self.delta\n",
    "    \n",
    "    def compute_grad(self):\n",
    "        batch_size = self.delta.shape[0]\n",
    "        \n",
    "        self.dW = np.matmul(self.x.T, self.delta) / batch_size\n",
    "        self.db = np.matmul(np.ones(batch_size), self.delta) / batch_size\n",
    "\n",
    "    def get_params(self):\n",
    "        return np.concatenate([self.W.ravel(), self.b], axis=0)\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        _W, _b = np.split(params, self.params_idxs)[:-1]\n",
    "        self.W = _W.reshape(self.W.shape)\n",
    "        self.b = _b\n",
    "    \n",
    "    def get_grads(self):\n",
    "        return np.concatenate([self.dW.ravel(), self.db], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_props(layers, x):\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_props(layers, delta):\n",
    "    batch_size = delta.shape[0]\n",
    "    \n",
    "    for i, layer in enumerate(layers[::-1]):\n",
    "        if i == 0: # 出力層の場合\n",
    "            layer.delta = delta # y - t\n",
    "            layer.compute_grad() # 勾配の計算\n",
    "        else: # 出力層以外の場合\n",
    "            delta = layer.b_prop(delta, W) # 逆伝播\n",
    "            layer.compute_grad() # 勾配の計算\n",
    "\n",
    "        W = layer.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(layers, eps):\n",
    "    for layer in layers:\n",
    "        layer.W -= eps * layer.dW\n",
    "        layer.b -= eps * layer.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dense(784, 100, relu, deriv_relu),\n",
    "    Dense(100, 100, relu, deriv_relu),\n",
    "    Dense(100, 10, softmax, deriv_softmax)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mst(x, t, eps=0.01):\n",
    "    # 順伝播\n",
    "    y = f_props(layers, x)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (- t * np_log(y)).sum(axis=1).mean()\n",
    "    \n",
    "    # 逆伝播\n",
    "    delta = y - t\n",
    "    b_props(layers, delta)\n",
    "\n",
    "    # パラメータの更新\n",
    "    update_params(layers, eps)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_mst(x, t):\n",
    "    # 順伝播\n",
    "    y = f_props(layers, x)\n",
    "    \n",
    "    # 誤差の計算\n",
    "    cost = (- t * np_log(y)).sum(axis=1).mean()\n",
    "    \n",
    "    return cost, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Valid Cost: 0.143, Valid Accuracy: 0.959\n",
      "EPOCH: 2, Valid Cost: 0.137, Valid Accuracy: 0.958\n",
      "EPOCH: 3, Valid Cost: 0.105, Valid Accuracy: 0.969\n",
      "EPOCH: 4, Valid Cost: 0.113, Valid Accuracy: 0.967\n",
      "EPOCH: 5, Valid Cost: 0.117, Valid Accuracy: 0.967\n",
      "EPOCH: 6, Valid Cost: 0.100, Valid Accuracy: 0.973\n",
      "EPOCH: 7, Valid Cost: 0.118, Valid Accuracy: 0.973\n",
      "EPOCH: 8, Valid Cost: 0.107, Valid Accuracy: 0.974\n",
      "EPOCH: 9, Valid Cost: 0.121, Valid Accuracy: 0.971\n",
      "EPOCH: 10, Valid Cost: 0.122, Valid Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    x_train_mnist, t_train_mnist = shuffle(x_train_mnist, t_train_mnist)\n",
    "    # オンライン学習\n",
    "    for x, t in zip(x_train_mnist, t_train_mnist):\n",
    "        cost = train_mst(x[None, :], t[None, :], eps=0.01)\n",
    "    \n",
    "    cost, y_pred = valid_mst(x_valid_mnist, t_valid_mnist)\n",
    "    accuracy = accuracy_score(t_valid_mnist.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(epoch + 1, cost, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
